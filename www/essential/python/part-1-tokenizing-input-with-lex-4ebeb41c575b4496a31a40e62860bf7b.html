<!doctype html>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="referrer" content="always">

  <meta name="twitter:card" value="summary">
  <meta name="twitter:site" content="@kjk">
  <meta name="twitter:title" content="Part 1 Tokenizing Input with Lex">
  
  <meta name="twitter:description" content="Part 1 Tokenizing Input with Lex">
  <meta name="twitter:creator" content="@kjk">
  <meta name="twitter:image" content="https://www.programming-books.io/covers/twitter/Python.png">
  
  <meta property="og:title" content="Part 1 Tokenizing Input with Lex">
  <meta property="og:type" content="article" />
  <meta property="og:url" content="https://www.programming-books.io/essential/python/part-1-tokenizing-input-with-lex-4ebeb41c575b4496a31a40e62860bf7b" />
  
  <meta property="og:description" content="Part 1 Tokenizing Input with Lex">
  <meta property="og:image" content="https://www.programming-books.io/covers/twitter/Python.png">

  <title>Python Lex-Yacc / Part 1 Tokenizing Input with Lex / Essential Python</title>
  <meta name="description" content="Python Lex-Yacc / Part 1 Tokenizing Input with Lex / Essential Python">
  <link rel="icon" href="/s/favicon.ico">
  <link href="/s/main.css" rel="stylesheet">
  <link href="/s/bundle.css" rel="stylesheet">
  <script src="/s/app-python.js" defer></script>
  <script src="/s/bundle.js" defer></script>
</head>

<body class="page">
  <script>
  function onLoad() {
    gBookTitle = "Essential Python";

    httpsMaybeRedirect();

    let opts = {
      target: document.getElementById("toc"),
      props: {
        parentIdx: -1,
        level: 0,
      },
    };
    new app.toc(opts);

    opts = {
      target: document.getElementById("search-parent"),
      props: {
        bookTitle: gBookTitle,
      },
    };
    new app.searchInput(opts);

    opts = {
      target: document.getElementById("page-toc"),
    };
    new app.pageToc(opts);

    opts = {
      target: document.getElementById("book-toc"),
    };
    new app.bookToc(opts);
  }
  document.addEventListener('DOMContentLoaded', onLoad);
</script>
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none">
  <symbol id="arrow-expanded" viewbox="0 0 16 16">
    <path fill="%23646465" d="M11 10H5.344L11 4.414V10z" />
  </symbol>

  <symbol id="arrow-not-expanded" viewbox="0 0 16 16">
    <path fill="%23646465" d="M6 4v8l4-4-4-4zm1 2.414L8.586 8 7 9.586V6.414z" />
  </symbol>

  <symbol id="icon-github" viewbox="0 0 496 512">
    <path
      d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z" />
  </symbol>

  <symbol id="icon-home" viewbox="0 0 576 512">
    <path
      d="M488 312.7V456c0 13.3-10.7 24-24 24H348c-6.6 0-12-5.4-12-12V356c0-6.6-5.4-12-12-12h-72c-6.6 0-12 5.4-12 12v112c0 6.6-5.4 12-12 12H112c-13.3 0-24-10.7-24-24V312.7c0-3.6 1.6-7 4.4-9.3l188-154.8c4.4-3.6 10.8-3.6 15.3 0l188 154.8c2.7 2.3 4.3 5.7 4.3 9.3zm83.6-60.9L488 182.9V44.4c0-6.6-5.4-12-12-12h-56c-6.6 0-12 5.4-12 12V117l-89.5-73.7c-17.7-14.6-43.3-14.6-61 0L4.4 251.8c-5.1 4.2-5.8 11.8-1.6 16.9l25.5 31c4.2 5.1 11.8 5.8 16.9 1.6l235.2-193.7c4.4-3.6 10.8-3.6 15.3 0l235.2 193.7c5.1 4.2 12.7 3.5 16.9-1.6l25.5-31c4.2-5.2 3.4-12.7-1.7-16.9z" />
  </symbol>

  <symbol id="icon-twitter" viewbox="0 0 512 512">
    <path
      d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z" />
  </symbol>

  <symbol id="icon-edit" viewbox="0 0 576 512">
    <path
      d="M402.6 83.2l90.2 90.2c3.8 3.8 3.8 10 0 13.8L274.4 405.6l-92.8 10.3c-12.4 1.4-22.9-9.1-21.5-21.5l10.3-92.8L388.8 83.2c3.8-3.8 10-3.8 13.8 0zm162-22.9l-48.8-48.8c-15.2-15.2-39.9-15.2-55.2 0l-35.4 35.4c-3.8 3.8-3.8 10 0 13.8l90.2 90.2c3.8 3.8 10 3.8 13.8 0l35.4-35.4c15.2-15.3 15.2-40 0-55.2zM384 346.2V448H64V128h229.8c3.2 0 6.2-1.3 8.5-3.5l40-40c7.6-7.6 2.2-20.5-8.5-20.5H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h352c26.5 0 48-21.5 48-48V306.2c0-10.7-12.9-16-20.5-8.5l-40 40c-2.2 2.3-3.5 5.3-3.5 8.5z" />
  </symbol>

  <symbol id="icon-star" viewbox="0 0 576 512">
    <path
      d="M528.1 171.5L382 150.2 316.7 17.8c-11.7-23.6-45.6-23.9-57.4 0L194 150.2 47.9 171.5c-26.2 3.8-36.7 36.1-17.7 54.6l105.7 103-25 145.5c-4.5 26.3 23.2 46 46.4 33.7L288 439.6l130.7 68.7c23.2 12.2 50.9-7.4 46.4-33.7l-25-145.5 105.7-103c19-18.5 8.5-50.8-17.7-54.6zM388.6 312.3l23.7 138.4L288 385.4l-124.3 65.3 23.7-138.4-100.6-98 139-20.2 62.2-126 62.2 126 139 20.2-100.6 98z" />
  </symbol>
</svg>
  <header class="page__header">
  <div class="page__header__left">
    <a id="link-home" href="index.html">
      <svg class="icon-home">
        <use xlink:href="#icon-home"></use>
      </svg>
      &nbsp;Essential Python</a>
  </div>
  <div class="page__header__center" id="search-parent">
  </div>
  <div class="page__header__right">
  </div>
</header>

  <div id="toc"></div>

  <div class="content">
    <div class="article">
      

<div style="display: flex; justify-content: space-between">
  <h1 class="title">Part 1 Tokenizing Input with Lex</h1>
  <a class="edit-link" style="font-size: 80%" href="https://notion.so/4ebeb41c575b4496a31a40e62860bf7b" rel="nofollow"
  target="_blank">suggest change</a>
</div>


      <p>There are two steps that the code from example 1 carried out: one was <em>tokenizing</em> the input, which means it looked for symbols that constitute the arithmetic expression, and the second step was <em>parsing</em>, which involves analysing the extracted tokens and evaluating the result.</p><p>This section provides a simple example of how to <em>tokenize</em> user input, and then breaks it down line by line.</p>
<div class="code-box lang-Plain Text">
	<div>
	<pre class="chroma">import ply.lex as lex

# List of token names. This is always required
tokens = [
   &#39;NUMBER&#39;,
   &#39;PLUS&#39;,
   &#39;MINUS&#39;,
   &#39;TIMES&#39;,
   &#39;DIVIDE&#39;,
   &#39;LPAREN&#39;,
   &#39;RPAREN&#39;,
]

# Regular expression rules for simple tokens
t_PLUS    = r&#39;\+&#39;
t_MINUS   = r&#39;-&#39;
t_TIMES   = r&#39;\*&#39;
t_DIVIDE  = r&#39;/&#39;
t_LPAREN  = r&#39;\(&#39;
t_RPAREN  = r&#39;\)&#39;

# A regular expression rule with some action code
def t_NUMBER(t):
    r&#39;\d+&#39;
    t.value = int(t.value)    
    return t

# Define a rule so we can track line numbers
def t_newline(t):
    r&#39;\n+&#39;
    t.lexer.lineno += len(t.value)

# A string containing ignored characters (spaces and tabs)
t_ignore  = &#39; \t&#39;

# Error handling rule
def t_error(t):
    print(&#34;Illegal character &#39;%s&#39;&#34; % t.value[0])
    t.lexer.skip(1)

# Build the lexer
lexer = lex.lex()

# Give the lexer some input
lexer.input(data)

# Tokenize
while True:
    tok = lexer.token()
    if not tok: 
        break      # No more input
    print(tok)</pre>
	</div>
	<div class="code-box-nav">
		
	</div>
</div><p>Save this file as <code>calclex.py</code>. Weâ€™ll be using this when building our Yacc parser.</p><hr id="94d1f7d3-d744-4f2e-97da-1488e79d8269"/><h1 id="30fdad2b-8a44-4887-9aed-fa2e00500592" class="">Breakdown<a class="header-anchor" href="#30fdad2b-8a44-4887-9aed-fa2e00500592" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 8 8"><path d="M5.88.03c-.18.01-.36.03-.53.09-.27.1-.53.25-.75.47a.5.5 0 1 0 .69.69c.11-.11.24-.17.38-.22.35-.12.78-.07 1.06.22.39.39.39 1.04 0 1.44l-1.5 1.5c-.44.44-.8.48-1.06.47-.26-.01-.41-.13-.41-.13a.5.5 0 1 0-.5.88s.34.22.84.25c.5.03 1.2-.16 1.81-.78l1.5-1.5c.78-.78.78-2.04 0-2.81-.28-.28-.61-.45-.97-.53-.18-.04-.38-.04-.56-.03zm-2 2.31c-.5-.02-1.19.15-1.78.75l-1.5 1.5c-.78.78-.78 2.04 0 2.81.56.56 1.36.72 2.06.47.27-.1.53-.25.75-.47a.5.5 0 1 0-.69-.69c-.11.11-.24.17-.38.22-.35.12-.78.07-1.06-.22-.39-.39-.39-1.04 0-1.44l1.5-1.5c.4-.4.75-.45 1.03-.44.28.01.47.09.47.09a.5.5 0 1 0 .44-.88s-.34-.2-.84-.22z"></path></svg></a></h1><ol id="7301d5e1-7de2-4db5-82c3-fe3810fcaeff" class="numbered-list" start="1"><li>Import the module using <code>import ply.lex</code></li><li>All lexers must provide a list called <code>tokens</code> that defines all of the possible token names that can be produced by the lexer. This list is always required.</li></ol>
<div class="code-box lang-Plain Text">
	<div>
	<pre class="chroma">tokens = [
   &#39;NUMBER&#39;,
   &#39;PLUS&#39;,
   &#39;MINUS&#39;,
   &#39;TIMES&#39;,
   &#39;DIVIDE&#39;,
   &#39;LPAREN&#39;,
   &#39;RPAREN&#39;,
]</pre>
	</div>
	<div class="code-box-nav">
		
	</div>
</div><p><code>tokens</code> could also be a tuple of strings (rather than a string), where each string denotes a token as before.</p><ol id="7304cd1b-3db2-4b3d-827e-cfa20331f1f1" class="numbered-list" start="1"><li>The regex rule for each string may be defined either as a string or as a function. In either case, the variable name should be prefixed by t_ to denote it is a rule for matching tokens.</li></ol><ul id="3889a527-1574-4ede-972e-79fa3af21ed0" class="bulleted-list"><li>For simple tokens, the regular expression can be specified as strings: <code>t_PLUS = r&#x27;\+&#x27;</code></li><li>If some kind of action needs to be performed, a token rule can be specified as a function.</li></ul>
<div class="code-box lang-Plain Text">
	<div>
	<pre class="chroma">def t_NUMBER(t):
    r&#39;\d+&#39;
    t.value = int(t.value)
    return t
Note, the rule is specified as a doc string within the function. The function accepts one argument which is an instance of `LexToken`, performs some action and then returns back the argument. 

If you want to use an external string as the regex rule for the function instead of specifying a doc string, consider the following example:

@TOKEN(identifier)         # identifier is a string holding the regex
def t_ID(t):
    ...      # actions

* An instance of `LexToken` object (let&#39;s call this object `t`) has the following attributes:
1) `t.type` which is the token type (as a string) (eg: `&#39;NUMBER&#39;`, `&#39;PLUS&#39;`, etc). By default, `t.type` is set to the name following the `t_` prefix.
2) `t.value` which is the lexeme (the actual text matched) 
3) `t.lineno` which is the current line number (this is not automatically updated, as the lexer knows nothing of line numbers). Update lineno using a function called `t_newline`.

## 

def t_newline(t):
    r&#39;\n+&#39;
    t.lexer.lineno += len(t.value)

##
4) `t.lexpos` which is the position of the token relative to the beginning of the input text.</pre>
	</div>
	<div class="code-box-nav">
		
	</div>
</div><ul id="74be6da5-034f-472b-b68d-b34a79a8ab24" class="bulleted-list"><li>If nothing is returned from a regex rule function, the token is discarded. If you want to discard a token, you can alternatively add t_ignore_ prefix to a regex rule variable instead of defining a function for the same rule.</li></ul>
<div class="code-box lang-Plain Text">
	<div>
	<pre class="chroma">def t_COMMENT(t):
    r&#39;\#.*&#39;
    pass
    # No return value. Token discarded

...Is the same as:

t_ignore_COMMENT = r&#39;\#.*&#39;
##

&lt;sup&gt;This is of course invalid if you&#39;re carrying out some action when you see a comment. In which case, use a function to define the regex rule.&lt;/sup&gt; 

If you haven&#39;t defined a token for some characters but still want to ignore it, use `t_ignore = &#34;&lt;characters to ignore&gt;&#34;` (these prefixes are necessary):          

t_ignore_COMMENT = r&#39;\#.*&#39;
t_ignore  = &#39; \t&#39;    # ignores spaces and tabs

##
- When building the master regex, lex will add the regexes specified in the file as follows: 
1) Tokens defined by functions are added in the same order as they appear in the file. 
2) Tokens defined by strings are added in decreasing order of the string length of the string defining the regex for that token.

If you are matching `==` and `=` in the same file, take advantage of these rules.
##
- Literals are tokens that are returned as they are. Both `t.type` and `t.value` will be set to the character itself.</pre>
	</div>
	<div class="code-box-nav">
		
	</div>
</div><p>Define a list of literals as such:</p>
<div class="code-box lang-Plain Text">
	<div>
	<pre class="chroma">literals = [ &#39;+&#39;, &#39;-&#39;, &#39;*&#39;, &#39;/&#39; ]

or,

literals = &#34;+-*/&#34;

##

It is possible to write token functions that perform additional actions when literals are matched. However, you&#39;ll need to set the token type appropriately. For example:

literals = [ &#39;{&#39;, &#39;}&#39; ]

def t_lbrace(t):
    r&#39;\{&#39;
    t.type = &#39;{&#39;  # Set token type to the expected literal (ABSOLUTE MUST if this is a literal)
    return t

##
- Handle errors with t_error function.

# Error handling rule
def t_error(t):
  print(&#34;Illegal character &#39;%s&#39;&#34; % t.value[0])
  t.lexer.skip(1) # skip the illegal token (don&#39;t process it)

In general, `t.lexer.skip(n)` skips n characters in the input string.</pre>
	</div>
	<div class="code-box-nav">
		
	</div>
</div><ol id="16741000-9730-4123-936d-7dc58180b32d" class="numbered-list" start="1"><li>Final preparations:</li></ol>
<div class="code-box lang-Plain Text">
	<div>
	<pre class="chroma">Build the lexer using `lexer = lex.lex()`.

##
 You can also put everything inside a class and call use instance of the class to define the lexer. Eg:

##  
   import ply.lex as lex  
   class MyLexer(object):            
         ...     # everything relating to token rules and error handling comes here as usual 

         # Build the lexer
         def build(self, **kwargs):
             self.lexer = lex.lex(module=self, **kwargs)

         def test(self, data):
             self.lexer.input(data)
             for token in self.lexer.token():
                 print(token)

         # Build the lexer and try it out

   m = MyLexer()
   m.build()           # Build the lexer
   m.test(&#34;3 + 4&#34;)     #

Provide input using `lexer.input(data)` where data is a string 

To get the tokens, use `lexer.token()` which returns tokens matched. You can iterate over lexer in a loop as in:

##

  for i in lexer: 
      print(i)</pre>
	</div>
	<div class="code-box-nav">
		
	</div>
</div>

      <div class="forum-link">
  Found a mistake? Have a question or improvement idea?
  <a href="#" onclick="showContact(); return false;">Let me know</a>.
</div>

      <form id="contact-form" action="https://formsubmit.co/kkowalczyk@gmail.com" method="POST">
  <p>
    <div class="contact-light">Feedback about page:</div>
    <input type="text" name="page-url" id="contact-page-url" readonly />
  </p>

  <p>
    <div class="contact-light">Feedback:</div>
    <textarea name="message" id="msg-for-chris"></textarea>
    <div class="contact-light">Optional: your email if you want me to get back to you: </div>
    <input type="email" name="email" />
    <input type="text" name="_honey" style="display:none">
  </p>

  <p>
    <button type="submit" class="contact-btn">
      Send Feedback
    </button>

    <button class="contact-btn" style="float: right;" onclick="hideContact(); return false;">
      Cancel
    </button>
  </p>

  <p>
    <div data-netlify-recaptcha></div>
  </p>
</form>


      <hr class="article-bottom-sep">
    </div>

    <div id="page-toc"></div>

    <div id="chapter-toc-wrapper">
      <hr />
      <div class="hdr">Table Of Contents</div>
      <div id="book-toc"></div>
    </div>
  </div>

  <footer class="page__footer">
  <div class="page__footer__left">
    Maintained by
    <a href="https://blog.kowalczyk.info" target="_blank">Krzysztof Kowalczyk</a>
  </div>
  <div class="share-me">
    <a href="https://twitter.com/intent/tweet?text=%22Essential%20Python%22%20-%20a%20free%20programming%20book&url=https%3a%2f%2fwww.programming-books.io%2fessential%2fpython%2f&via=kjk">Share
      <b>Essential Python</b> on&nbsp;
      <svg class="icon-twitter">
        <use xlink:href="#icon-twitter"></use>
      </svg>
    </a>
  </div>
  <div class="page__footer__right">
    
  </div>
</footer>

  

</body>

</html>